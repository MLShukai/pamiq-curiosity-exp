forward_dynamics:
  _target_: exp.trainers.forward_dynamics.HiddenStateFDTrainer
  partial_optimizer:
    _target_: torch.optim.SGD
    _partial_: true
    lr: 1e-4
    momentum: 0.9
    nesterov: true
    weight_decay: 1e-4
  seq_len: 256
  max_samples: 32
  imagination_length:  ${shared.max_imagination_steps}
  min_new_data_count: 128

policy:
  _target_: exp.trainers.ppo_policy.PPOHiddenStatePiVTrainer
  partial_optimizer:
    _target_: torch.optim.SGD
    _partial_: true
    lr: 1e-4
    momentum: 0.9
    nesterov: true
    weight_decay: 1e-4
  gamma: ${python.eval:"1 - 1 / 1000"} # n ステップ先の報酬まで考慮する
  gae_lambda: 0.95
  norm_advantage: true
  entropy_coef: 0.01
  seq_len: 256
  max_samples: 32
  min_new_data_count: 128
