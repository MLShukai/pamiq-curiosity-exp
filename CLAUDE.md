# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Commands

### Development Setup

- `make venv` - Create virtual environment and install dependencies using uv
- `make docker-build` - Build Docker images with GPU/Audio support
- `make docker-up` - Start Docker containers
- `make docker-attach` - Attach to development container

### Development Workflow

- `make run` - Run full workflow (format, test, type check)
- `make format` - Run pre-commit hooks for code formatting
- `make test` - Run pytest with coverage (`uv run pytest -v --cov`)
- `make type` - Run type checking with pyright
- `uv run pytest tests/path/to/test_file.py::TestClass::test_method` - Run single test

### Docker Operations

- `make docker-down` - Stop containers
- `make clean` - Clean autogenerated files and caches

## Architecture Overview

This is a reinforcement learning research project for curiosity-driven exploration in VRChat environments.

### Core Components

**Agents** (`src/pamiq_curiosity_exp/agents/`)

- `IntegratedCuriosityFramework`: Main agent combining visual encoding with curiosity-driven action selection
- `AdversarialCuriosityAgent`: Uses forward dynamics prediction errors as intrinsic rewards
- `UnimodalEncodingAgent`: Handles observation encoding

**Models** (`src/pamiq_curiosity_exp/models/`)

- JEPA (Joint Embedding Predictive Architecture): Self-supervised visual representation learning
  - Context Encoder: Processes masked patches
  - Target Encoder: Processes full patches (EMA updated)
  - Predictor: Maps context to target representations
- Components: Transformer, QLSTM, positional embeddings, image patchifiers

**Environment** (`src/pamiq_curiosity_exp/envs/`)

- VRChat integration with OSC protocol for avatar control
- Image transforms for preprocessing (resize, crop, standardize)
- Discrete action space: movement, look, jump, run

**Trainers** (`src/pamiq_curiosity_exp/trainers/`)

- `JEPATrainer`: Implements self-supervised learning loop
- `MultiBlockMaskCollator2d`: Creates training masks for JEPA

### Key Dependencies

- PAMIQ Core framework for agent-based learning
- PAMIQ VRChat for environment interaction
- PyTorch for deep learning
- MLflow for experiment tracking

### Testing Guidelines

- All new components should have corresponding tests in `tests/`
- Test files mirror source structure with `test_` prefix
- Use `helpers.py` for common test utilities

## あなたのポジション

あなたはプロのpython developperかつ機械学習の実験のプロフェッショナルです。

## 要件

- Python 3.12以降で実装
- 型アノテーションは必須。ただし typingモジュールのListやTupleよりBuiltinの listやtupleを用いる。
- Python3.12以降で可能な構文は積極的に用いる。Enumやリテラルの条件分岐にmatch文を使うなどね。
- TypeVarやGenericは使わない。Python3.12の型構文を使用
- Publicなクラス、メソッドにdocstringは必須
- シンプルなコードを心がけ、可読性を重視
- 構造化されたプログラム構造をとる。
- ドキュメンテーションは Google Style, 型アノテーションを必須にするので docstringの中に型情報はいらない。Englishで記述する。コンストラクタ `__init__`のdocstringはクラスではなくメソッドの後に記述する。
- testも記述。pytestを使用。pytest-mock, pytest-covがある。

### テストの方針

- 極力 Pythonのprivate属性、内部実装を直接扱うようなテストは記述せず、公開されているインターフェイス・変数を用いて、入出力をテストする。
- テストの直接的なターゲットが抽象クラスの場合は、ダミー実装を `Impl` prefixをつけて実装する。依存関係に抽象クラスが含まれていた場合は Mockする。
- 1つのテストメソッドは単一の機能検証のみにフォーカスすることが望ましい。
